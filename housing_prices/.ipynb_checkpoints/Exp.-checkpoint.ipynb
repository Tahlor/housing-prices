{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/medic/github/housing-prices/housing_prices\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import pandas as pd\n",
    "def extract_main_dataset(path=None):\n",
    "\tif path is None:\n",
    "\t\t#path = r'/medic/github/housing-prices/data/train.csv'\n",
    "\t\tpath = r'/medic/github/housing-prices/output/processed_features.csv'\n",
    "\tdf = pd.read_csv(path)\n",
    "\ty = df[\"SalePrice\"].values\n",
    "\tx = df.drop([\"SalePrice\"], axis=1).values\n",
    "\treturn (x, y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done recoding\n",
      "{'CentralAir': 'ordinal', 'GarageFinish': 'ordinal', 'Utilities': 'ordinal', 'FireplaceQu': 'ordinal', 'PoolQC': 'ordinal', 'BsmtFinType2': 'ordinal', 'BsmtFinType1': 'ordinal', 'BsmtExposure': 'ordinal', 'GarageQual': 'ordinal', 'ExterQual': 'ordinal', 'ExterCond': 'ordinal', 'MasVnrType': 'ordinal', 'GarageCond': 'ordinal', 'BsmtQual': 'ordinal', 'Fence': 'ordinal', 'Functional': 'ordinal', 'PavedDrive': 'ordinal', 'KitchenQual': 'ordinal', 'HeatingQC': 'ordinal', 'BsmtCond': 'ordinal'}\n",
      "               time_index\n",
      "YrSold Season            \n",
      "2006   0         0.984570\n",
      "       1         0.994274\n",
      "       2         1.022098\n",
      "       3         0.965096\n",
      "2007   0         0.943806\n",
      "       1         1.012006\n",
      "       2         0.977910\n",
      "       3         1.122818\n",
      "2008   0         0.995425\n",
      "       1         0.998463\n",
      "       2         1.008838\n",
      "       3         1.040135\n",
      "2009   0         1.023074\n",
      "       1         1.005261\n",
      "       2         0.956458\n",
      "       3         0.975102\n",
      "2010   0         0.990235\n",
      "       1         0.984429\n",
      "              neighborhood_index\n",
      "Neighborhood                    \n",
      "Blmngtn                 1.008916\n",
      "Blueste                 0.968314\n",
      "BrDale                  0.870401\n",
      "BrkSide                 0.924873\n",
      "ClearCr                 1.022089\n",
      "CollgCr                 1.073021\n",
      "Crawfor                 1.067008\n",
      "Edwards                 0.878722\n",
      "Gilbert                 1.103783\n",
      "IDOTRR                  0.754476\n",
      "...                          ...\n",
      "NoRidge                 1.179562\n",
      "NridgHt                 1.264242\n",
      "OldTown                 0.814010\n",
      "SWISU                   0.801738\n",
      "Sawyer                  0.919584\n",
      "SawyerW                 1.012476\n",
      "Somerst                 1.177355\n",
      "StoneBr                 1.273868\n",
      "Timber                  1.111138\n",
      "Veenker                 1.171181\n",
      "\n",
      "[25 rows x 1 columns]\n",
      "Done creating new features\n",
      "Done standardizing features\n",
      "[MICE] Completing matrix with shape (1460, 1)\n",
      "[MICE] Starting imputation round 1/110, elapsed time 0.000\n",
      "[MICE] Starting imputation round 2/110, elapsed time 0.001\n",
      "[MICE] Starting imputation round 3/110, elapsed time 0.001\n",
      "[MICE] Starting imputation round 4/110, elapsed time 0.001\n",
      "[MICE] Starting imputation round 5/110, elapsed time 0.002\n",
      "[MICE] Starting imputation round 6/110, elapsed time 0.002\n",
      "[MICE] Starting imputation round 7/110, elapsed time 0.002\n",
      "[MICE] Starting imputation round 8/110, elapsed time 0.002\n",
      "[MICE] Starting imputation round 9/110, elapsed time 0.003\n",
      "[MICE] Starting imputation round 10/110, elapsed time 0.003\n",
      "[MICE] Starting imputation round 11/110, elapsed time 0.003\n",
      "[MICE] Starting imputation round 12/110, elapsed time 0.003\n",
      "[MICE] Starting imputation round 13/110, elapsed time 0.004\n",
      "[MICE] Starting imputation round 14/110, elapsed time 0.004\n",
      "[MICE] Starting imputation round 15/110, elapsed time 0.004\n",
      "[MICE] Starting imputation round 16/110, elapsed time 0.004\n",
      "[MICE] Starting imputation round 17/110, elapsed time 0.005\n",
      "[MICE] Starting imputation round 18/110, elapsed time 0.005\n",
      "[MICE] Starting imputation round 19/110, elapsed time 0.005\n",
      "[MICE] Starting imputation round 20/110, elapsed time 0.005\n",
      "[MICE] Starting imputation round 21/110, elapsed time 0.006\n",
      "[MICE] Starting imputation round 22/110, elapsed time 0.006\n",
      "[MICE] Starting imputation round 23/110, elapsed time 0.006\n",
      "[MICE] Starting imputation round 24/110, elapsed time 0.006\n",
      "[MICE] Starting imputation round 25/110, elapsed time 0.007\n",
      "[MICE] Starting imputation round 26/110, elapsed time 0.007\n",
      "[MICE] Starting imputation round 27/110, elapsed time 0.007\n",
      "[MICE] Starting imputation round 28/110, elapsed time 0.007\n",
      "[MICE] Starting imputation round 29/110, elapsed time 0.008\n",
      "[MICE] Starting imputation round 30/110, elapsed time 0.008\n",
      "[MICE] Starting imputation round 31/110, elapsed time 0.008\n",
      "[MICE] Starting imputation round 32/110, elapsed time 0.008\n",
      "[MICE] Starting imputation round 33/110, elapsed time 0.009\n",
      "[MICE] Starting imputation round 34/110, elapsed time 0.009\n",
      "[MICE] Starting imputation round 35/110, elapsed time 0.009\n",
      "[MICE] Starting imputation round 36/110, elapsed time 0.009\n",
      "[MICE] Starting imputation round 37/110, elapsed time 0.010\n",
      "[MICE] Starting imputation round 38/110, elapsed time 0.010\n",
      "[MICE] Starting imputation round 39/110, elapsed time 0.010\n",
      "[MICE] Starting imputation round 40/110, elapsed time 0.010\n",
      "[MICE] Starting imputation round 41/110, elapsed time 0.011\n",
      "[MICE] Starting imputation round 42/110, elapsed time 0.011\n",
      "[MICE] Starting imputation round 43/110, elapsed time 0.011\n",
      "[MICE] Starting imputation round 44/110, elapsed time 0.011\n",
      "[MICE] Starting imputation round 45/110, elapsed time 0.012\n",
      "[MICE] Starting imputation round 46/110, elapsed time 0.012\n",
      "[MICE] Starting imputation round 47/110, elapsed time 0.012\n",
      "[MICE] Starting imputation round 48/110, elapsed time 0.012\n",
      "[MICE] Starting imputation round 49/110, elapsed time 0.013\n",
      "[MICE] Starting imputation round 50/110, elapsed time 0.013\n",
      "[MICE] Starting imputation round 51/110, elapsed time 0.013\n",
      "[MICE] Starting imputation round 52/110, elapsed time 0.013\n",
      "[MICE] Starting imputation round 53/110, elapsed time 0.014\n",
      "[MICE] Starting imputation round 54/110, elapsed time 0.014\n",
      "[MICE] Starting imputation round 55/110, elapsed time 0.014\n",
      "[MICE] Starting imputation round 56/110, elapsed time 0.014\n",
      "[MICE] Starting imputation round 57/110, elapsed time 0.015\n",
      "[MICE] Starting imputation round 58/110, elapsed time 0.015\n",
      "[MICE] Starting imputation round 59/110, elapsed time 0.015\n",
      "[MICE] Starting imputation round 60/110, elapsed time 0.015\n",
      "[MICE] Starting imputation round 61/110, elapsed time 0.016\n",
      "[MICE] Starting imputation round 62/110, elapsed time 0.016\n",
      "[MICE] Starting imputation round 63/110, elapsed time 0.016\n",
      "[MICE] Starting imputation round 64/110, elapsed time 0.016\n",
      "[MICE] Starting imputation round 65/110, elapsed time 0.017\n",
      "[MICE] Starting imputation round 66/110, elapsed time 0.017\n",
      "[MICE] Starting imputation round 67/110, elapsed time 0.017\n",
      "[MICE] Starting imputation round 68/110, elapsed time 0.017\n",
      "[MICE] Starting imputation round 69/110, elapsed time 0.018\n",
      "[MICE] Starting imputation round 70/110, elapsed time 0.018\n",
      "[MICE] Starting imputation round 71/110, elapsed time 0.018\n",
      "[MICE] Starting imputation round 72/110, elapsed time 0.018\n",
      "[MICE] Starting imputation round 73/110, elapsed time 0.019\n",
      "[MICE] Starting imputation round 74/110, elapsed time 0.019\n",
      "[MICE] Starting imputation round 75/110, elapsed time 0.019\n",
      "[MICE] Starting imputation round 76/110, elapsed time 0.019\n",
      "[MICE] Starting imputation round 77/110, elapsed time 0.020\n",
      "[MICE] Starting imputation round 78/110, elapsed time 0.020\n",
      "[MICE] Starting imputation round 79/110, elapsed time 0.020\n",
      "[MICE] Starting imputation round 80/110, elapsed time 0.020\n",
      "[MICE] Starting imputation round 81/110, elapsed time 0.021\n",
      "[MICE] Starting imputation round 82/110, elapsed time 0.021\n",
      "[MICE] Starting imputation round 83/110, elapsed time 0.021\n",
      "[MICE] Starting imputation round 84/110, elapsed time 0.021\n",
      "[MICE] Starting imputation round 85/110, elapsed time 0.022\n",
      "[MICE] Starting imputation round 86/110, elapsed time 0.022\n",
      "[MICE] Starting imputation round 87/110, elapsed time 0.022\n",
      "[MICE] Starting imputation round 88/110, elapsed time 0.022\n",
      "[MICE] Starting imputation round 89/110, elapsed time 0.023\n",
      "[MICE] Starting imputation round 90/110, elapsed time 0.023\n",
      "[MICE] Starting imputation round 91/110, elapsed time 0.023\n",
      "[MICE] Starting imputation round 92/110, elapsed time 0.024\n",
      "[MICE] Starting imputation round 93/110, elapsed time 0.024\n",
      "[MICE] Starting imputation round 94/110, elapsed time 0.024\n",
      "[MICE] Starting imputation round 95/110, elapsed time 0.024\n",
      "[MICE] Starting imputation round 96/110, elapsed time 0.025\n",
      "[MICE] Starting imputation round 97/110, elapsed time 0.025\n",
      "[MICE] Starting imputation round 98/110, elapsed time 0.025\n",
      "[MICE] Starting imputation round 99/110, elapsed time 0.025\n",
      "[MICE] Starting imputation round 100/110, elapsed time 0.026\n",
      "[MICE] Starting imputation round 101/110, elapsed time 0.026\n",
      "[MICE] Starting imputation round 102/110, elapsed time 0.026\n",
      "[MICE] Starting imputation round 103/110, elapsed time 0.026\n",
      "[MICE] Starting imputation round 104/110, elapsed time 0.027\n",
      "[MICE] Starting imputation round 105/110, elapsed time 0.027\n",
      "[MICE] Starting imputation round 106/110, elapsed time 0.027\n",
      "[MICE] Starting imputation round 107/110, elapsed time 0.027\n",
      "[MICE] Starting imputation round 108/110, elapsed time 0.028\n",
      "[MICE] Starting imputation round 109/110, elapsed time 0.028\n",
      "[MICE] Starting imputation round 110/110, elapsed time 0.028\n",
      "[MICE] Completing matrix with shape (1459, 1)\n",
      "[MICE] Starting imputation round 1/110, elapsed time 0.000\n",
      "[MICE] Starting imputation round 2/110, elapsed time 0.001\n",
      "[MICE] Starting imputation round 3/110, elapsed time 0.001\n",
      "[MICE] Starting imputation round 4/110, elapsed time 0.001\n",
      "[MICE] Starting imputation round 5/110, elapsed time 0.001\n",
      "[MICE] Starting imputation round 6/110, elapsed time 0.002\n",
      "[MICE] Starting imputation round 7/110, elapsed time 0.002\n",
      "[MICE] Starting imputation round 8/110, elapsed time 0.002\n",
      "[MICE] Starting imputation round 9/110, elapsed time 0.002\n",
      "[MICE] Starting imputation round 10/110, elapsed time 0.003\n",
      "[MICE] Starting imputation round 11/110, elapsed time 0.003\n",
      "[MICE] Starting imputation round 12/110, elapsed time 0.003\n",
      "[MICE] Starting imputation round 13/110, elapsed time 0.003\n",
      "[MICE] Starting imputation round 14/110, elapsed time 0.004\n",
      "[MICE] Starting imputation round 15/110, elapsed time 0.004\n",
      "[MICE] Starting imputation round 16/110, elapsed time 0.004\n",
      "[MICE] Starting imputation round 17/110, elapsed time 0.004\n",
      "[MICE] Starting imputation round 18/110, elapsed time 0.005\n",
      "[MICE] Starting imputation round 19/110, elapsed time 0.005\n",
      "[MICE] Starting imputation round 20/110, elapsed time 0.005\n",
      "[MICE] Starting imputation round 21/110, elapsed time 0.005\n",
      "[MICE] Starting imputation round 22/110, elapsed time 0.006\n",
      "[MICE] Starting imputation round 23/110, elapsed time 0.006\n",
      "[MICE] Starting imputation round 24/110, elapsed time 0.006\n",
      "[MICE] Starting imputation round 25/110, elapsed time 0.006\n",
      "[MICE] Starting imputation round 26/110, elapsed time 0.007\n",
      "[MICE] Starting imputation round 27/110, elapsed time 0.007\n",
      "[MICE] Starting imputation round 28/110, elapsed time 0.007\n",
      "[MICE] Starting imputation round 29/110, elapsed time 0.007\n",
      "[MICE] Starting imputation round 30/110, elapsed time 0.008\n",
      "[MICE] Starting imputation round 31/110, elapsed time 0.008\n",
      "[MICE] Starting imputation round 32/110, elapsed time 0.008\n",
      "[MICE] Starting imputation round 33/110, elapsed time 0.008\n",
      "[MICE] Starting imputation round 34/110, elapsed time 0.009\n",
      "[MICE] Starting imputation round 35/110, elapsed time 0.009\n",
      "[MICE] Starting imputation round 36/110, elapsed time 0.009\n",
      "[MICE] Starting imputation round 37/110, elapsed time 0.009\n",
      "[MICE] Starting imputation round 38/110, elapsed time 0.010\n",
      "[MICE] Starting imputation round 39/110, elapsed time 0.010\n",
      "[MICE] Starting imputation round 40/110, elapsed time 0.010\n",
      "[MICE] Starting imputation round 41/110, elapsed time 0.010\n",
      "[MICE] Starting imputation round 42/110, elapsed time 0.011\n",
      "[MICE] Starting imputation round 43/110, elapsed time 0.011\n",
      "[MICE] Starting imputation round 44/110, elapsed time 0.011\n",
      "[MICE] Starting imputation round 45/110, elapsed time 0.011\n",
      "[MICE] Starting imputation round 46/110, elapsed time 0.012\n",
      "[MICE] Starting imputation round 47/110, elapsed time 0.012\n",
      "[MICE] Starting imputation round 48/110, elapsed time 0.012\n",
      "[MICE] Starting imputation round 49/110, elapsed time 0.012\n",
      "[MICE] Starting imputation round 50/110, elapsed time 0.013\n",
      "[MICE] Starting imputation round 51/110, elapsed time 0.013\n",
      "[MICE] Starting imputation round 52/110, elapsed time 0.013\n",
      "[MICE] Starting imputation round 53/110, elapsed time 0.014\n",
      "[MICE] Starting imputation round 54/110, elapsed time 0.014\n",
      "[MICE] Starting imputation round 55/110, elapsed time 0.014\n",
      "[MICE] Starting imputation round 56/110, elapsed time 0.014\n",
      "[MICE] Starting imputation round 57/110, elapsed time 0.015\n",
      "[MICE] Starting imputation round 58/110, elapsed time 0.015\n",
      "[MICE] Starting imputation round 59/110, elapsed time 0.015\n",
      "[MICE] Starting imputation round 60/110, elapsed time 0.015\n",
      "[MICE] Starting imputation round 61/110, elapsed time 0.015\n",
      "[MICE] Starting imputation round 62/110, elapsed time 0.016\n",
      "[MICE] Starting imputation round 63/110, elapsed time 0.016\n",
      "[MICE] Starting imputation round 64/110, elapsed time 0.016\n",
      "[MICE] Starting imputation round 65/110, elapsed time 0.016\n",
      "[MICE] Starting imputation round 66/110, elapsed time 0.017\n",
      "[MICE] Starting imputation round 67/110, elapsed time 0.017\n",
      "[MICE] Starting imputation round 68/110, elapsed time 0.017\n",
      "[MICE] Starting imputation round 69/110, elapsed time 0.017\n",
      "[MICE] Starting imputation round 70/110, elapsed time 0.018\n",
      "[MICE] Starting imputation round 71/110, elapsed time 0.018\n",
      "[MICE] Starting imputation round 72/110, elapsed time 0.018\n",
      "[MICE] Starting imputation round 73/110, elapsed time 0.018\n",
      "[MICE] Starting imputation round 74/110, elapsed time 0.019\n",
      "[MICE] Starting imputation round 75/110, elapsed time 0.019\n",
      "[MICE] Starting imputation round 76/110, elapsed time 0.019\n",
      "[MICE] Starting imputation round 77/110, elapsed time 0.019\n",
      "[MICE] Starting imputation round 78/110, elapsed time 0.020\n",
      "[MICE] Starting imputation round 79/110, elapsed time 0.020\n",
      "[MICE] Starting imputation round 80/110, elapsed time 0.020\n",
      "[MICE] Starting imputation round 81/110, elapsed time 0.020\n",
      "[MICE] Starting imputation round 82/110, elapsed time 0.021\n",
      "[MICE] Starting imputation round 83/110, elapsed time 0.021\n",
      "[MICE] Starting imputation round 84/110, elapsed time 0.021\n",
      "[MICE] Starting imputation round 85/110, elapsed time 0.021\n",
      "[MICE] Starting imputation round 86/110, elapsed time 0.022\n",
      "[MICE] Starting imputation round 87/110, elapsed time 0.022\n",
      "[MICE] Starting imputation round 88/110, elapsed time 0.022\n",
      "[MICE] Starting imputation round 89/110, elapsed time 0.022\n",
      "[MICE] Starting imputation round 90/110, elapsed time 0.023\n",
      "[MICE] Starting imputation round 91/110, elapsed time 0.023\n",
      "[MICE] Starting imputation round 92/110, elapsed time 0.023\n",
      "[MICE] Starting imputation round 93/110, elapsed time 0.024\n",
      "[MICE] Starting imputation round 94/110, elapsed time 0.024\n",
      "[MICE] Starting imputation round 95/110, elapsed time 0.024\n",
      "[MICE] Starting imputation round 96/110, elapsed time 0.024\n",
      "[MICE] Starting imputation round 97/110, elapsed time 0.025\n",
      "[MICE] Starting imputation round 98/110, elapsed time 0.025\n",
      "[MICE] Starting imputation round 99/110, elapsed time 0.025\n",
      "[MICE] Starting imputation round 100/110, elapsed time 0.025\n",
      "[MICE] Starting imputation round 101/110, elapsed time 0.026\n",
      "[MICE] Starting imputation round 102/110, elapsed time 0.026\n",
      "[MICE] Starting imputation round 103/110, elapsed time 0.026\n",
      "[MICE] Starting imputation round 104/110, elapsed time 0.026\n",
      "[MICE] Starting imputation round 105/110, elapsed time 0.027\n",
      "[MICE] Starting imputation round 106/110, elapsed time 0.027\n",
      "[MICE] Starting imputation round 107/110, elapsed time 0.028\n",
      "[MICE] Starting imputation round 108/110, elapsed time 0.028\n",
      "[MICE] Starting imputation round 109/110, elapsed time 0.029\n",
      "[MICE] Starting imputation round 110/110, elapsed time 0.029\n",
      "Done imputing variables\n",
      "Done creating dummies\n",
      "Done excluding vacuous variables\n"
     ]
    }
   ],
   "source": [
    "def reimport():\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    import model\n",
    "    import prep_features\n",
    "    import import_data\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    path_test = r'../data/test_data3.csv'\n",
    "    path_training = r'../data/train.csv'\n",
    "\n",
    "    raw_training = import_data.process_data(path_training)\n",
    "    test_df = import_data.process_data(path_test)\n",
    "    training_df = raw_training\n",
    "    features, targets, test_features, test_targets = prep_features.main(training_df, test_df, drop_outliers=False, use_log=True)\n",
    "\n",
    "    targets = targets.drop([\"SalePriceMiscVal\"], axis=1)\n",
    "    test_targets = test_targets.drop([\"SalePriceMiscVal\"], axis=1)\n",
    "\n",
    "    targets = targets[\"SalePrice\"]\n",
    "    test_targets = test_targets[\"SalePrice\"]\n",
    "    IGNORE=[\"Id\"]\n",
    "    globals().update(locals())\n",
    "\n",
    "    \n",
    "reimport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import main\n",
    "MODEL_TYPE = \"GradientBoosting\"\n",
    "\n",
    "def run(keep_list, model=\"ElasticNet\", reduce_features=False, feats=None, test_feats=None):\n",
    "    if feats is None:\n",
    "        feats=features\n",
    "    if test_feats is None:\n",
    "        test_feats=test_features\n",
    "    if not \"Id\" in keep_list:\n",
    "        keep_list.append(\"Id\")\n",
    "    tr_f = feats[keep_list]\n",
    "    ts_f = test_feats[keep_list]\n",
    "    #print(tr_f.shape)\n",
    "    if reduce_features:\n",
    "        keep_features = main.feature_reduction(tr_f, targets)\n",
    "        ts_f = ts_f[keep_features]\n",
    "        tr_f = tr_f[keep_features]\n",
    "    my_model = main.create_model(tr_f, targets, ignore_features= IGNORE, type=model, X_validation=ts_f, y_validation=test_targets) # Lasso\n",
    "\n",
    "\n",
    "    if model not in [\"NN\"]:\n",
    "        #main.cv(my_model, tr_f, targets)\n",
    "        my_model.model.fit(tr_f.drop(IGNORE,1), targets)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    #rmse_cv(my_model, features, targets)\n",
    "    test_score = get_test_score(my_model, ts_f, test_targets)\n",
    "    feature_importances = main.plot_features(my_model, tr_f)\n",
    "    return test_score, feature_importances, my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(1460, 254)\n",
      "Test score: 0.11712751899111241\n",
      "(1460, 254)\n",
      "Test score: 0.11712751899111241\n",
      "(1460, 254)\n",
      "Test score: 0.11712751899111241\n",
      "(1460, 254)\n",
      "Test score: 0.117127629369706\n",
      "(1460, 254)\n",
      "Test score: 0.11712751899111241\n",
      "(1460, 254)\n",
      "Test score: 0.11712769169665545\n",
      "(1460, 254)\n",
      "Test score: 0.11712574707919543\n",
      "(1460, 254)\n",
      "Test score: 0.1172505897199122\n",
      "(1460, 254)\n",
      "Test score: 0.11712574161744996\n",
      "(1460, 254)\n",
      "Test score: 0.11717942319844622\n",
      "(1460, 254)\n",
      "Test score: 0.11712576360098897\n",
      "(1460, 254)\n",
      "Test score: 0.11728334568518851\n",
      "(1460, 254)\n",
      "Test score: 0.11712895853783574\n",
      "(1460, 254)\n",
      "Test score: 0.11967143711270883\n",
      "(1460, 254)\n",
      "Test score: 0.1171257422472179\n",
      "(1460, 254)\n",
      "Test score: 0.11722314895690918\n",
      "(1460, 254)\n",
      "Test score: 0.11712578499885479\n",
      "(1460, 254)\n",
      "Test score: 0.11729933884409766\n",
      "Updating master list!\n",
      "(1460, 114)\n",
      "Test score: 0.1230290610682867\n",
      "(1460, 114)\n",
      "Test score: 0.12302719386001086\n",
      "(1460, 114)\n",
      "Test score: 0.12303071522600545\n",
      "(1460, 114)\n",
      "Test score: 0.1230238788763435\n",
      "(1460, 114)\n",
      "Test score: 0.12303071522600545\n",
      "(1460, 114)\n",
      "Test score: 0.12303071522600545\n",
      "Updating master list!\n",
      "(1460, 111)\n",
      "Test score: 0.12313996449001587\n",
      "(1460, 111)\n",
      "Test score: 0.123135616275653\n",
      "(1460, 111)\n",
      "Test score: 0.12313997298261223\n",
      "(1460, 111)\n",
      "Test score: 0.12310195719633467\n",
      "(1460, 111)\n",
      "Test score: 0.12312541422656449\n",
      "(1460, 111)\n",
      "Test score: 0.12312977535339402\n",
      "Updating master list!\n",
      "(1460, 109)\n",
      "Test score: 0.12307691211848942\n",
      "(1460, 109)\n",
      "Test score: 0.12307385254375801\n",
      "(1460, 109)\n",
      "Test score: 0.12308204269745156\n",
      "(1460, 109)\n",
      "Test score: 0.12308567785053884\n",
      "(1460, 109)\n",
      "Test score: 0.12306902259604313\n",
      "(1460, 109)\n",
      "Test score: 0.12305978836184384\n",
      "Updating master list!\n",
      "(1460, 109)\n",
      "Test score: 0.12313002773772015\n",
      "(1460, 109)\n",
      "Test score: 0.1231866760863059\n",
      "(1460, 109)\n",
      "Test score: 0.12310235710963381\n",
      "(1460, 109)\n",
      "Test score: 0.1230247701727479\n",
      "(1460, 109)\n",
      "Test score: 0.12334015882134451\n",
      "(1460, 109)\n",
      "Test score: 0.12308968446170566\n",
      "Updating master list!\n",
      "(1460, 109)\n",
      "Test score: 0.12412248988454766\n",
      "(1460, 109)\n",
      "Test score: 0.12402745239373052\n",
      "(1460, 109)\n",
      "Test score: 0.12412978626276917\n",
      "(1460, 109)\n",
      "Test score: 0.12391315867763954\n",
      "(1460, 109)\n",
      "Test score: 0.12425635731117936\n",
      "(1460, 109)\n",
      "Test score: 0.12298421321783329\n",
      "Updating master list!\n",
      "(1460, 108)\n",
      "Test score: 0.12317737455974358\n",
      "(1460, 108)\n",
      "Test score: 0.12317883145960704\n",
      "(1460, 108)\n",
      "Test score: 0.12321645353855296\n",
      "(1460, 108)\n",
      "Test score: 0.12317766641238895\n",
      "(1460, 108)\n",
      "Test score: 0.12316969566022977\n",
      "(1460, 108)\n",
      "Test score: 0.12317842874340625\n",
      "(1460, 108)\n",
      "Test score: 0.12315242811870356\n",
      "(1460, 108)\n",
      "Test score: 0.12319545495146177\n",
      "(1460, 108)\n",
      "Test score: 0.1235012332349987\n",
      "(1460, 108)\n",
      "Test score: 0.12318074503708004\n",
      "(1460, 108)\n",
      "Test score: 0.12309533765864726\n",
      "(1460, 108)\n",
      "Test score: 0.12327526058838095\n",
      "Updating master list!\n",
      "(1460, 107)\n",
      "Test score: 0.1230281056525344\n",
      "(1460, 107)\n",
      "Test score: 0.1249111027430331\n",
      "(1460, 107)\n",
      "Test score: 0.12336194032849392\n",
      "(1460, 107)\n",
      "Test score: 0.12376974331586563\n",
      "(1460, 107)\n",
      "Test score: 0.12585917293614804\n",
      "(1460, 107)\n",
      "Test score: 0.1247501302861681\n",
      "Updating master list!\n",
      "(1460, 107)\n",
      "Test score: 0.123167846382118\n",
      "(1460, 107)\n",
      "Test score: 0.12389076736281887\n",
      "(1460, 107)\n",
      "Test score: 0.12340784609704149\n",
      "(1460, 107)\n",
      "Test score: 0.12396348258422497\n",
      "(1460, 107)\n",
      "Test score: 0.12401898172517671\n",
      "(1460, 107)\n",
      "Test score: 0.12532976546816715\n",
      "Updating master list!\n",
      "(1460, 107)\n",
      "Test score: 0.12312627712510388\n",
      "(1460, 107)\n",
      "Test score: 0.12310426353747585\n",
      "(1460, 107)\n",
      "Test score: 0.12312913950426929\n",
      "(1460, 107)\n",
      "Test score: 0.12306160654444664\n",
      "(1460, 107)\n",
      "Test score: 0.12326019524095798\n",
      "(1460, 107)\n",
      "Test score: 0.1230018992624907\n",
      "Updating master list!\n",
      "(1460, 107)\n",
      "Test score: 0.12306505797200036\n",
      "(1460, 107)\n",
      "Test score: 0.1230409938368641\n",
      "(1460, 107)\n",
      "Test score: 0.1230909777453157\n",
      "(1460, 107)\n",
      "Test score: 0.12314073281723503\n",
      "(1460, 107)\n",
      "Test score: 0.12310188704006861\n",
      "(1460, 107)\n",
      "Test score: 0.12312111025105785\n",
      "Updating master list!\n",
      "(1460, 107)\n",
      "Test score: 0.12308210337921156\n",
      "(1460, 107)\n",
      "Test score: 0.12315498342207437\n",
      "(1460, 107)\n",
      "Test score: 0.12309193218820848\n",
      "(1460, 107)\n",
      "Test score: 0.12305435177674795\n",
      "(1460, 107)\n",
      "Test score: 0.12393475158112845\n",
      "(1460, 107)\n",
      "Test score: 0.12304702957434488\n",
      "Updating master list!\n",
      "(1460, 107)\n",
      "Test score: 0.12315984400976675\n",
      "(1460, 107)\n",
      "Test score: 0.12324550367738134\n",
      "(1460, 107)\n",
      "Test score: 0.12306936729033077\n",
      "(1460, 107)\n",
      "Test score: 0.1233805451031331\n",
      "(1460, 107)\n",
      "Test score: 0.12344728230377694\n",
      "(1460, 107)\n",
      "Test score: 0.12377242603137244\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12301205118799716\n",
      "(1460, 106)\n",
      "Test score: 0.12300335906865362\n",
      "(1460, 106)\n",
      "Test score: 0.12301331053720507\n",
      "(1460, 106)\n",
      "Test score: 0.12302600295507667\n",
      "(1460, 106)\n",
      "Test score: 0.1230227834147729\n",
      "(1460, 106)\n",
      "Test score: 0.12302690911221055\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12283064720857144\n",
      "(1460, 106)\n",
      "Test score: 0.12286787582659688\n",
      "(1460, 106)\n",
      "Test score: 0.12295315764334355\n",
      "(1460, 106)\n",
      "Test score: 0.12297587625686571\n",
      "(1460, 106)\n",
      "Test score: 0.12296029314683642\n",
      "(1460, 106)\n",
      "Test score: 0.12290205156769969\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12295776959903774\n",
      "(1460, 106)\n",
      "Test score: 0.12295442089424824\n",
      "(1460, 106)\n",
      "Test score: 0.12291869295594329\n",
      "(1460, 106)\n",
      "Test score: 0.12283426530155546\n",
      "(1460, 106)\n",
      "Test score: 0.12283151582913526\n",
      "(1460, 106)\n",
      "Test score: 0.12284625867733359\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12292709159857396\n",
      "(1460, 106)\n",
      "Test score: 0.12295818624142615\n",
      "(1460, 106)\n",
      "Test score: 0.1228721802787608\n",
      "(1460, 106)\n",
      "Test score: 0.12283958342588604\n",
      "(1460, 106)\n",
      "Test score: 0.12280894182262952\n",
      "(1460, 106)\n",
      "Test score: 0.1232006412056435\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12267880659806\n",
      "(1460, 106)\n",
      "Test score: 0.12267559308699864\n",
      "(1460, 106)\n",
      "Test score: 0.12267867023534978\n",
      "(1460, 106)\n",
      "Test score: 0.12277103238027491\n",
      "(1460, 106)\n",
      "Test score: 0.12272159702587822\n",
      "(1460, 106)\n",
      "Test score: 0.12282751902141885\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.1228258856258959\n",
      "(1460, 106)\n",
      "Test score: 0.12278029507828207\n",
      "(1460, 106)\n",
      "Test score: 0.12272992906904562\n",
      "(1460, 106)\n",
      "Test score: 0.1228505808942957\n",
      "(1460, 106)\n",
      "Test score: 0.12280350420507544\n",
      "(1460, 106)\n",
      "Test score: 0.12341641396111933\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12358463916138121\n",
      "(1460, 106)\n",
      "Test score: 0.12418226491177507\n",
      "(1460, 106)\n",
      "Test score: 0.12297004946536062\n",
      "(1460, 106)\n",
      "Test score: 0.12268210780821161\n",
      "(1460, 106)\n",
      "Test score: 0.12284295498584014\n",
      "(1460, 106)\n",
      "Test score: 0.1229616378912852\n",
      "Updating master list!\n",
      "(1460, 105)\n",
      "Test score: 0.12272167697472633\n",
      "(1460, 105)\n",
      "Test score: 0.12268803102713584\n",
      "(1460, 105)\n",
      "Test score: 0.12272656350916548\n",
      "(1460, 105)\n",
      "Test score: 0.12273531057384711\n",
      "(1460, 105)\n",
      "Test score: 0.12272533229672467\n",
      "(1460, 105)\n",
      "Test score: 0.1227295652766371\n",
      "Updating master list!\n",
      "(1460, 105)\n",
      "Test score: 0.12537387813985365\n",
      "(1460, 105)\n",
      "Test score: 0.12536300483494034\n",
      "(1460, 105)\n",
      "Test score: 0.12581130919501066\n",
      "(1460, 105)\n",
      "Test score: 0.125914494027069\n",
      "(1460, 105)\n",
      "Test score: 0.1270550550950727\n",
      "(1460, 105)\n",
      "Test score: 0.12290642888984309\n",
      "Updating master list!\n",
      "(1460, 105)\n",
      "Test score: 0.12274412575058967\n",
      "(1460, 105)\n",
      "Test score: 0.12281400914877821\n",
      "(1460, 105)\n",
      "Test score: 0.12279455669152832\n",
      "(1460, 105)\n",
      "Test score: 0.12268720615123457\n",
      "(1460, 105)\n",
      "Test score: 0.12293992818607187\n",
      "(1460, 105)\n",
      "Test score: 0.12293690271389396\n",
      "Updating master list!\n",
      "(1460, 105)\n",
      "Test score: 0.12244505169444621\n",
      "(1460, 105)\n",
      "Test score: 0.12238516975418269\n",
      "(1460, 105)\n",
      "Test score: 0.1223578273161474\n",
      "(1460, 105)\n",
      "Test score: 0.12226564805979778\n",
      "(1460, 105)\n",
      "Test score: 0.12236270514033788\n",
      "(1460, 105)\n",
      "Test score: 0.12258937719139797\n",
      "Updating master list!\n",
      "(1460, 105)\n",
      "Test score: 0.12258050570056421\n",
      "(1460, 105)\n",
      "Test score: 0.1225789509480225\n",
      "(1460, 105)\n",
      "Test score: 0.12258051972883627\n",
      "(1460, 105)\n",
      "Test score: 0.12274981897276513\n",
      "(1460, 105)\n",
      "Test score: 0.12274148088867572\n",
      "(1460, 105)\n",
      "Test score: 0.12269804634817369\n",
      "Updating master list!\n",
      "(1460, 105)\n",
      "Test score: 0.122531605536989\n",
      "(1460, 105)\n",
      "Test score: 0.12254302574152245\n",
      "(1460, 105)\n",
      "Test score: 0.12254721678566823\n",
      "(1460, 105)\n",
      "Test score: 0.12258506180542852\n",
      "(1460, 105)\n",
      "Test score: 0.12259269259957213\n",
      "(1460, 105)\n",
      "Test score: 0.12265745544644162\n",
      "Updating master list!\n",
      "(1460, 105)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.12256126260903728\n",
      "(1460, 105)\n",
      "Test score: 0.12256959469877038\n",
      "(1460, 105)\n",
      "Test score: 0.12256176997793232\n",
      "(1460, 105)\n",
      "Test score: 0.12259254682780851\n",
      "(1460, 105)\n",
      "Test score: 0.12273138605992964\n",
      "(1460, 105)\n",
      "Test score: 0.12269838024737335\n",
      "Updating master list!\n",
      "(1460, 105)\n",
      "Test score: 0.12263402833585978\n",
      "(1460, 105)\n",
      "Test score: 0.12265479467611556\n",
      "(1460, 105)\n",
      "Test score: 0.1226457111968564\n",
      "(1460, 105)\n",
      "Test score: 0.1226389021981461\n",
      "(1460, 105)\n",
      "Test score: 0.12458184667072075\n",
      "(1460, 105)\n",
      "Test score: 0.12269738477746336\n",
      "Updating master list!\n",
      "(1460, 105)\n",
      "Test score: 0.1227594460240442\n",
      "(1460, 105)\n",
      "Test score: 0.1227795709073246\n",
      "(1460, 105)\n",
      "Test score: 0.12270944127896284\n",
      "(1460, 105)\n",
      "Test score: 0.12265884816435801\n",
      "(1460, 105)\n",
      "Test score: 0.12261659268605295\n",
      "(1460, 105)\n",
      "Test score: 0.12289630076863349\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12262584621653616\n",
      "(1460, 106)\n",
      "Test score: 0.12262219578881814\n",
      "(1460, 106)\n",
      "Test score: 0.12262442829498488\n",
      "(1460, 106)\n",
      "Test score: 0.12263201441407788\n",
      "(1460, 106)\n",
      "Test score: 0.12262835015328795\n",
      "(1460, 106)\n",
      "Test score: 0.12263951984742612\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12300052447453753\n",
      "(1460, 106)\n",
      "Test score: 0.12295658904913949\n",
      "(1460, 106)\n",
      "Test score: 0.12294364979736758\n",
      "(1460, 106)\n",
      "Test score: 0.1226143826538809\n",
      "(1460, 106)\n",
      "Test score: 0.12271366191303201\n",
      "(1460, 106)\n",
      "Test score: 0.12318342829544184\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12260291459799813\n",
      "(1460, 106)\n",
      "Test score: 0.12255713108118713\n",
      "(1460, 106)\n",
      "Test score: 0.12264038911316273\n",
      "(1460, 106)\n",
      "Test score: 0.12265631357668387\n",
      "(1460, 106)\n",
      "Test score: 0.12261078834930482\n",
      "(1460, 106)\n",
      "Test score: 0.12261928954542999\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12260760915464468\n",
      "(1460, 106)\n",
      "Test score: 0.1226019432778481\n",
      "(1460, 106)\n",
      "Test score: 0.12260854098173347\n",
      "(1460, 106)\n",
      "Test score: 0.12261299847165033\n",
      "(1460, 106)\n",
      "Test score: 0.12261062810950606\n",
      "(1460, 106)\n",
      "Test score: 0.12262617815100571\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12323268443167985\n",
      "(1460, 106)\n",
      "Test score: 0.12320245301276402\n",
      "(1460, 106)\n",
      "Test score: 0.1231247901179698\n",
      "(1460, 106)\n",
      "Test score: 0.12294392037216137\n",
      "(1460, 106)\n",
      "Test score: 0.123829311942488\n",
      "(1460, 106)\n",
      "Test score: 0.12260179706949922\n",
      "Updating master list!\n",
      "(1460, 107)\n",
      "Test score: 0.12255608950202505\n",
      "(1460, 107)\n",
      "Test score: 0.12254039959956085\n",
      "(1460, 107)\n",
      "Test score: 0.12255520079057533\n",
      "(1460, 107)\n",
      "Test score: 0.1225744660168931\n",
      "(1460, 107)\n",
      "Test score: 0.12258188973136357\n",
      "(1460, 107)\n",
      "Test score: 0.1225921550825042\n",
      "Updating master list!\n",
      "(1460, 107)\n",
      "Test score: 0.12236533859902789\n",
      "(1460, 107)\n",
      "Test score: 0.12401543182924157\n",
      "(1460, 107)\n",
      "Test score: 0.12252438758867279\n",
      "(1460, 107)\n",
      "Test score: 0.12327522085545028\n",
      "(1460, 107)\n",
      "Test score: 0.123220838727065\n",
      "(1460, 107)\n",
      "Test score: 0.12443457837741184\n",
      "Updating master list!\n",
      "(1460, 107)\n",
      "Test score: 0.12250942563783265\n",
      "(1460, 107)\n",
      "Test score: 0.12248735242767698\n",
      "(1460, 107)\n",
      "Test score: 0.12248261844386081\n",
      "(1460, 107)\n",
      "Test score: 0.12241284730102739\n",
      "(1460, 107)\n",
      "Test score: 0.12255341393790263\n",
      "(1460, 107)\n",
      "Test score: 0.12245924797944911\n",
      "Updating master list!\n",
      "(1460, 107)\n",
      "Test score: 0.12245753873588178\n",
      "(1460, 107)\n",
      "Test score: 0.12246275627554576\n",
      "(1460, 107)\n",
      "Test score: 0.12245925151112867\n",
      "(1460, 107)\n",
      "Test score: 0.12244101257083007\n",
      "(1460, 107)\n",
      "Test score: 0.12243808110224459\n",
      "(1460, 107)\n",
      "Test score: 0.12242164557407997\n",
      "Updating master list!\n",
      "(1460, 107)\n",
      "Test score: 0.12248170297749608\n",
      "(1460, 107)\n",
      "Test score: 0.12241187744697465\n",
      "(1460, 107)\n",
      "Test score: 0.12289977484437092\n",
      "(1460, 107)\n",
      "Test score: 0.1232612577955437\n",
      "(1460, 107)\n",
      "Test score: 0.12293224791500727\n",
      "(1460, 107)\n",
      "Test score: 0.12242880608743259\n",
      "Updating master list!\n",
      "(1460, 107)\n",
      "Test score: 0.12235177913511182\n",
      "(1460, 107)\n",
      "Test score: 0.12230757450925893\n",
      "(1460, 107)\n",
      "Test score: 0.12244962301481248\n",
      "(1460, 107)\n",
      "Test score: 0.12229768977267567\n",
      "(1460, 107)\n",
      "Test score: 0.12228332364547\n",
      "(1460, 107)\n",
      "Test score: 0.12247242238412669\n",
      "Updating master list!\n",
      "(1460, 107)\n",
      "Test score: 0.12237532103008966\n",
      "(1460, 107)\n",
      "Test score: 0.12237544547890344\n",
      "(1460, 107)\n",
      "Test score: 0.12237545163918515\n",
      "(1460, 107)\n",
      "Test score: 0.12237885609897745\n",
      "(1460, 107)\n",
      "Test score: 0.12237812068009388\n",
      "(1460, 107)\n",
      "Test score: 0.12237955273326695\n",
      "Updating master list!\n",
      "(1460, 107)\n",
      "Test score: 0.12221471248517655\n",
      "(1460, 107)\n",
      "Test score: 0.12249035893751835\n",
      "(1460, 107)\n",
      "Test score: 0.12221077848853151\n",
      "(1460, 107)\n",
      "Test score: 0.12254368722438003\n",
      "(1460, 107)\n",
      "Test score: 0.12258621476675792\n",
      "(1460, 107)\n",
      "Test score: 0.12272182638347515\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12217508924020751\n",
      "(1460, 106)\n",
      "Test score: 0.12226211803408593\n",
      "(1460, 106)\n",
      "Test score: 0.12215037442743372\n",
      "(1460, 106)\n",
      "Test score: 0.12222820812759531\n",
      "(1460, 106)\n",
      "Test score: 0.12219306040708842\n",
      "(1460, 106)\n",
      "Test score: 0.12227949491443882\n",
      "Updating master list!\n",
      "(1460, 107)\n",
      "Test score: 0.12227197039919023\n",
      "(1460, 107)\n",
      "Test score: 0.1222196924348464\n",
      "(1460, 107)\n",
      "Test score: 0.12226544426262421\n",
      "(1460, 107)\n",
      "Test score: 0.12224670206124233\n",
      "(1460, 107)\n",
      "Test score: 0.12224598427679573\n",
      "(1460, 107)\n",
      "Test score: 0.12221552748715168\n",
      "Updating master list!\n",
      "(1460, 108)\n",
      "Test score: 0.12218101092834666\n",
      "(1460, 108)\n",
      "Test score: 0.12216434691434791\n",
      "(1460, 108)\n",
      "Test score: 0.12217256824925711\n",
      "(1460, 108)\n",
      "Test score: 0.12221913996238737\n",
      "(1460, 108)\n",
      "Test score: 0.12220243656950598\n",
      "(1460, 108)\n",
      "Test score: 0.12237166985633519\n",
      "Updating master list!\n",
      "(1460, 109)\n",
      "Test score: 0.12259911763914677\n",
      "(1460, 109)\n",
      "Test score: 0.12249319785551523\n",
      "(1460, 109)\n",
      "Test score: 0.12259447940425965\n",
      "(1460, 109)\n",
      "Test score: 0.1224711964818568\n",
      "(1460, 109)\n",
      "Test score: 0.12232752473303332\n",
      "(1460, 109)\n",
      "Test score: 0.1221859542308526\n",
      "Updating master list!\n",
      "(1460, 109)\n",
      "Test score: 0.12232179985896902\n",
      "(1460, 109)\n",
      "Test score: 0.12230703733274925\n",
      "(1460, 109)\n",
      "Test score: 0.12224756061954006\n",
      "(1460, 109)\n",
      "Test score: 0.1221423023021655\n",
      "(1460, 109)\n",
      "Test score: 0.12215819681328137\n",
      "(1460, 109)\n",
      "Test score: 0.12216821440927357\n",
      "Updating master list!\n",
      "(1460, 108)\n",
      "Test score: 0.12236671024060902\n",
      "(1460, 108)\n",
      "Test score: 0.12156320322335712\n",
      "(1460, 108)\n",
      "Test score: 0.12307471143721296\n",
      "(1460, 108)\n",
      "Test score: 0.12412969343032469\n",
      "(1460, 108)\n",
      "Test score: 0.12156272377241975\n",
      "(1460, 108)\n",
      "Test score: 0.12280172326694758\n",
      "Updating master list!\n",
      "(1460, 108)\n",
      "Test score: 0.12226466210379401\n",
      "(1460, 108)\n",
      "Test score: 0.12230166551279321\n",
      "(1460, 108)\n",
      "Test score: 0.12227333816265039\n",
      "(1460, 108)\n",
      "Test score: 0.12223093784132201\n",
      "(1460, 108)\n",
      "Test score: 0.12224499651189454\n",
      "(1460, 108)\n",
      "Test score: 0.12219378602383012\n",
      "Updating master list!\n",
      "(1460, 109)\n",
      "Test score: 0.12211975420707193\n",
      "(1460, 109)\n",
      "Test score: 0.1220931116751644\n",
      "(1460, 109)\n",
      "Test score: 0.12212117081393328\n",
      "(1460, 109)\n",
      "Test score: 0.12216171217071102\n",
      "(1460, 109)\n",
      "Test score: 0.12215527684941141\n",
      "(1460, 109)\n",
      "Test score: 0.12222201755456942\n",
      "Updating master list!\n",
      "(1460, 109)\n",
      "Test score: 0.12233107551230415\n",
      "(1460, 109)\n",
      "Test score: 0.12242906512940521\n",
      "(1460, 109)\n",
      "Test score: 0.12230512598822856\n",
      "(1460, 109)\n",
      "Test score: 0.12222615919917891\n",
      "(1460, 109)\n",
      "Test score: 0.12223282555913809\n",
      "(1460, 109)\n",
      "Test score: 0.12209600399458127\n",
      "Updating master list!\n",
      "(1460, 109)\n",
      "Test score: 0.12201437206882325\n",
      "(1460, 109)\n",
      "Test score: 0.12199964530864192\n",
      "(1460, 109)\n",
      "Test score: 0.12212546333624595\n",
      "(1460, 109)\n",
      "Test score: 0.12223901276821136\n",
      "(1460, 109)\n",
      "Test score: 0.12204470804764662\n",
      "(1460, 109)\n",
      "Test score: 0.12195726474720063\n",
      "Updating master list!\n",
      "(1460, 108)\n",
      "Test score: 0.12189768884886006\n",
      "(1460, 108)\n",
      "Test score: 0.12162115994034968\n",
      "(1460, 108)\n",
      "Test score: 0.12192859870115277\n",
      "(1460, 108)\n",
      "Test score: 0.12213848164343034\n",
      "(1460, 108)\n",
      "Test score: 0.12194120148730316\n",
      "(1460, 108)\n",
      "Test score: 0.12205853872852104\n",
      "Updating master list!\n",
      "(1460, 108)\n",
      "Test score: 0.1219513940296549\n",
      "(1460, 108)\n",
      "Test score: 0.12195532319725431\n",
      "(1460, 108)\n",
      "Test score: 0.12195147233810923\n",
      "(1460, 108)\n",
      "Test score: 0.12166659781111455\n",
      "(1460, 108)\n",
      "Test score: 0.12195049410621422\n",
      "(1460, 108)\n",
      "Test score: 0.1216180209762658\n",
      "Updating master list!\n",
      "(1460, 108)\n",
      "Test score: 0.12189276979695413\n",
      "(1460, 108)\n",
      "Test score: 0.12164664876221808\n",
      "(1460, 108)\n",
      "Test score: 0.12196208494459185\n",
      "(1460, 108)\n",
      "Test score: 0.12184373331644555\n",
      "(1460, 108)\n",
      "Test score: 0.12181709157999344\n",
      "(1460, 108)\n",
      "Test score: 0.12157385135866593\n",
      "Updating master list!\n",
      "(1460, 108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.1217369041255698\n",
      "(1460, 108)\n",
      "Test score: 0.1217812310932353\n",
      "(1460, 108)\n",
      "Test score: 0.12173577595147493\n",
      "(1460, 108)\n",
      "Test score: 0.1217254590088128\n",
      "(1460, 108)\n",
      "Test score: 0.1217294365952125\n",
      "(1460, 108)\n",
      "Test score: 0.12172751745430131\n",
      "Updating master list!\n",
      "(1460, 108)\n",
      "Test score: 0.12170235269395768\n",
      "(1460, 108)\n",
      "Test score: 0.12170189602342196\n",
      "(1460, 108)\n",
      "Test score: 0.12170178809137151\n",
      "(1460, 108)\n",
      "Test score: 0.12169361683198512\n",
      "(1460, 108)\n",
      "Test score: 0.12170161690273334\n",
      "(1460, 108)\n",
      "Test score: 0.12163996460303274\n",
      "Updating master list!\n",
      "(1460, 108)\n",
      "Test score: 0.12163929975763628\n",
      "(1460, 108)\n",
      "Test score: 0.12193781821272662\n",
      "(1460, 108)\n",
      "Test score: 0.12164049893317895\n",
      "(1460, 108)\n",
      "Test score: 0.12170801535545758\n",
      "(1460, 108)\n",
      "Test score: 0.1217110837883897\n",
      "(1460, 108)\n",
      "Test score: 0.12173452806498226\n",
      "Updating master list!\n",
      "(1460, 108)\n",
      "Test score: 0.12172573232999549\n",
      "(1460, 108)\n",
      "Test score: 0.12176419248256037\n",
      "(1460, 108)\n",
      "Test score: 0.1217146879722349\n",
      "(1460, 108)\n",
      "Test score: 0.12167994139465722\n",
      "(1460, 108)\n",
      "Test score: 0.12167782916107789\n",
      "(1460, 108)\n",
      "Test score: 0.12161528445293293\n",
      "Updating master list!\n",
      "Best model\n",
      "(1460, 108)\n",
      "Test score: 0.12165621924636198\n",
      "{'BedroomAbvGr_cont_trans_quadratic', 'Exterior1st_HdBoard_orig_categ', 'Neighborhood_Edwards_orig_categ', 'Neighborhood_NridgHt_orig_categ', 'SummerSale_orig_categ', 'GarageCars_cont_trans_quadratic', 'PoolQC_ord_trans_quadratic', 'BsmtHalfBath_cont_trans_quadratic', 'ScreenPorch_cont_trans_scale01', 'Foundation_BrkTil_orig_categ', 'time_index_cont_trans_log', 'Exterior1st_MetalSd_orig_categ', 'TotRmsAbvGrd_cont_trans_normal', 'GarageArea_cont_trans_log', 'MasVnrType_ord_trans_inverse', 'LotShape_IR1_orig_categ', 'HeatingQC_ord_trans_log', 'GarageType_Detchd_orig_categ', 'PavedDrive_ord_trans_quadratic', 'Neighborhood_NWAmes_orig_categ', 'YrSold_2008_orig_categ', 'SaleCondition_Abnorml_orig_categ', 'MSSubClass_70_orig_categ', 'Neighborhood_NoRidge_orig_categ', 'LandContour_Bnk_orig_categ', 'Neighborhood_NAmes_orig_categ', 'BsmtFullBath_cont_trans_inverse', 'PrchSQ_cont_trans_inverse', 'BsmtUnfSF_cont_trans_scale01', 'Neighborhood_Mitchel_orig_categ', 'BldgType_1Fam_orig_categ', 'LargeHouse_orig_categ', 'neighborhood_index_cont_trans_normal', 'YrSold_2010_orig_categ', 'RemodelAge_cont_trans_log', 'Condition1_RRAe_orig_categ', 'HouseStyle_2Story_orig_categ', 'GarageAgeInv_cont_trans_quadratic', 'Neighborhood_Crawfor_orig_categ', 'OverallQual_cont_trans_log', '1stFlrSF_cont_trans_quadratic', 'Neighborhood_OldTown_orig_categ', 'LotFrontage_cont_trans_log', 'BsmtFinSF2_cont_trans_normal', 'OpenPorchSF_cont_trans_normal', 'LowQualFinSF_cont_trans_log', 'Neighborhood_ClearCr_orig_categ', 'SQFperRoom_cont_trans_quadratic', 'Neighborhood_StoneBr_orig_categ', 'KitchenAbvGr_cont_trans_log', 'MSZoning_C (all)_orig_categ', 'Condition1_Norm_orig_categ', 'BsmtExposure_ord_trans_quadratic', 'SaleCondition_Family_orig_categ', 'ExterQual_ord_trans_log', 'Exterior1st_Wd Sdng_orig_categ', 'Condition1_Artery_orig_categ', 'GarageType_Attchd_orig_categ', 'RoofStyle_Hip_orig_categ', 'RoofMatl_WdShngl_orig_categ', 'LotConfig_CulDSac_orig_categ', 'MSZoning_FV_orig_categ', 'BsmtFinType1_ord_trans_quadratic', 'WoodDeckSF_cont_trans_scale01', 'FullBath_cont_trans_quadratic', 'GarageIdx_cont_trans_root', 'Season_1_orig_categ', '3SsnPorch_cont_trans_inverse', 'Exterior1st_BrkFace_orig_categ', 'LotConfig_FR2_orig_categ', 'SaleType_COD_orig_categ', 'TotalBsmtSF_cont_trans_quadratic', 'MasVnrArea_cont_trans_scale01', 'MSZoning_RM_orig_categ', '2ndFlrSF_cont_trans_root', 'Functional_ord_trans_inverse', 'Heating_GasW_orig_categ', 'EnclosedPorch_cont_trans_quadratic', 'SaleCondition_Normal_orig_categ', 'Fence_ord_trans_quadratic', 'BsmtFinType2_ord_trans_quadratic', 'Condition2_PosN_orig_categ', 'LotConfig_Corner_orig_categ', 'Neighborhood_Somerst_orig_categ', 'GrLivArea_cont_trans_log', 'BsmtQual_ord_trans_log', 'CentralAir_ord_trans_normal', 'BsmtFinSF1_cont_trans_normal', 'KitchenQual_ord_trans_normal', 'Utilities_ord_trans_root', 'Fireplaces_cont_trans_normal', 'Neighborhood_BrkSide_orig_categ', 'PoolArea_cont_trans_root', 'ExterCond_ord_trans_quadratic', 'LotArea_cont_trans_log', 'MoSold_cont_trans_inverse', 'Foundation_PConc_orig_categ', 'OverallCond_cont_trans_log', 'MiscVal_cont_trans_inverse', 'GarageQual_ord_trans_scale01', 'LandSlope_Mod_orig_categ', 'MSSubClass_30_orig_categ', 'TotalSQF_cont_trans_normal', 'HouseAge_cont_trans_normal', 'SaleType_WD_orig_categ', 'Heating_Grav_orig_categ', 'LandContour_HLS_orig_categ'}\n",
      "(1460, 254)\n",
      "Test score: 0.11728485098745746\n",
      "(1460, 254)\n",
      "Test score: 0.11731985662850931\n",
      "(1460, 254)\n",
      "Test score: 0.1172104564900847\n",
      "(1460, 254)\n",
      "Test score: 0.11712758683575204\n",
      "(1460, 254)\n",
      "Test score: 0.11961669052992066\n",
      "(1460, 254)\n",
      "Test score: 0.11752921347606339\n",
      "Updating master list!\n",
      "(1460, 114)\n",
      "Test score: 0.12420083322421392\n",
      "(1460, 114)\n",
      "Test score: 0.12410585348267482\n",
      "(1460, 114)\n",
      "Test score: 0.12420494190127239\n",
      "(1460, 114)\n",
      "Test score: 0.1239832028402097\n",
      "(1460, 114)\n",
      "Test score: 0.12432900719117011\n",
      "(1460, 114)\n",
      "Test score: 0.12303319621382815\n",
      "Updating master list!\n",
      "(1460, 110)\n",
      "Test score: 0.12298049751915677\n",
      "(1460, 110)\n",
      "Test score: 0.12468340349868945\n",
      "(1460, 110)\n",
      "Test score: 0.12312514383264589\n",
      "(1460, 110)\n",
      "Test score: 0.12385781130052628\n",
      "(1460, 110)\n",
      "Test score: 0.12381008097162795\n",
      "(1460, 110)\n",
      "Test score: 0.12498903997764688\n",
      "Updating master list!\n",
      "(1460, 109)\n",
      "Test score: 0.12306613860168886\n",
      "(1460, 109)\n",
      "Test score: 0.12313177988529628\n",
      "(1460, 109)\n",
      "Test score: 0.12311519303196777\n",
      "(1460, 109)\n",
      "Test score: 0.12299731679075684\n",
      "(1460, 109)\n",
      "Test score: 0.1233791366709438\n",
      "(1460, 109)\n",
      "Test score: 0.12330042807021\n",
      "Updating master list!\n",
      "(1460, 109)\n",
      "Test score: 0.12287970849200192\n",
      "(1460, 109)\n",
      "Test score: 0.122903263524156\n",
      "(1460, 109)\n",
      "Test score: 0.12289453508839555\n",
      "(1460, 109)\n",
      "Test score: 0.12293016169677484\n",
      "(1460, 109)\n",
      "Test score: 0.12293810244143265\n",
      "(1460, 109)\n",
      "Test score: 0.12300055543024552\n",
      "Updating master list!\n",
      "(1460, 109)\n",
      "Test score: 0.12282863499108404\n",
      "(1460, 109)\n",
      "Test score: 0.12276786762481844\n",
      "(1460, 109)\n",
      "Test score: 0.12279267745526526\n",
      "(1460, 109)\n",
      "Test score: 0.12293401862288644\n",
      "(1460, 109)\n",
      "Test score: 0.12290826740708917\n",
      "(1460, 109)\n",
      "Test score: 0.12315719654907693\n",
      "Updating master list!\n",
      "(1460, 109)\n",
      "Test score: 0.12574371399628698\n",
      "(1460, 109)\n",
      "Test score: 0.12572078035923162\n",
      "(1460, 109)\n",
      "Test score: 0.12614446171660898\n",
      "(1460, 109)\n",
      "Test score: 0.12600965060934302\n",
      "(1460, 109)\n",
      "Test score: 0.12748195740678508\n",
      "(1460, 109)\n",
      "Test score: 0.12307246404070725\n",
      "Updating master list!\n",
      "(1460, 108)\n",
      "Test score: 0.12274092406752359\n",
      "(1460, 108)\n",
      "Test score: 0.12274795666550568\n",
      "(1460, 108)\n",
      "Test score: 0.12275019062581911\n",
      "(1460, 108)\n",
      "Test score: 0.12280993929007071\n",
      "(1460, 108)\n",
      "Test score: 0.12291843450914541\n",
      "(1460, 108)\n",
      "Test score: 0.12291914115763668\n",
      "Updating master list!\n",
      "(1460, 109)\n",
      "Test score: 0.12272905187721123\n",
      "(1460, 109)\n",
      "Test score: 0.1227216624373756\n",
      "(1460, 109)\n",
      "Test score: 0.12272907176396897\n",
      "(1460, 109)\n",
      "Test score: 0.12290067729403814\n",
      "(1460, 109)\n",
      "Test score: 0.12289829839971962\n",
      "(1460, 109)\n",
      "Test score: 0.12285472362617826\n",
      "Updating master list!\n",
      "(1460, 109)\n",
      "Test score: 0.12285673827747555\n",
      "(1460, 109)\n",
      "Test score: 0.12278749895309694\n",
      "(1460, 109)\n",
      "Test score: 0.12274335173466287\n",
      "(1460, 109)\n",
      "Test score: 0.12289467817270622\n",
      "(1460, 109)\n",
      "Test score: 0.12279521352963514\n",
      "(1460, 109)\n",
      "Test score: 0.12351966863975584\n",
      "Updating master list!\n",
      "(1460, 109)\n",
      "Test score: 0.1227263022013657\n",
      "(1460, 109)\n",
      "Test score: 0.12299625444701463\n",
      "(1460, 109)\n",
      "Test score: 0.12271509575887533\n",
      "(1460, 109)\n",
      "Test score: 0.12274682340718131\n",
      "(1460, 109)\n",
      "Test score: 0.12276624564700901\n",
      "(1460, 109)\n",
      "Test score: 0.12278247954792632\n",
      "Updating master list!\n",
      "(1460, 108)\n",
      "Test score: 0.12292520049758995\n",
      "(1460, 108)\n",
      "Test score: 0.12289906858858983\n",
      "(1460, 108)\n",
      "Test score: 0.12296358310732014\n",
      "(1460, 108)\n",
      "Test score: 0.12289944364118358\n",
      "(1460, 108)\n",
      "Test score: 0.12291983141210207\n",
      "(1460, 108)\n",
      "Test score: 0.12289866550226225\n",
      "(1460, 108)\n",
      "Test score: 0.12289987603486902\n",
      "(1460, 108)\n",
      "Test score: 0.12291433528299678\n",
      "(1460, 108)\n",
      "Test score: 0.12322847791445463\n",
      "(1460, 108)\n",
      "Test score: 0.12290109818556612\n",
      "(1460, 108)\n",
      "Test score: 0.1228434990933337\n",
      "(1460, 108)\n",
      "Test score: 0.12299618544663452\n",
      "Updating master list!\n",
      "(1460, 107)\n",
      "Test score: 0.12288499005520116\n",
      "(1460, 107)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.12286547670425589\n",
      "(1460, 107)\n",
      "Test score: 0.12283105909587036\n",
      "(1460, 107)\n",
      "Test score: 0.12275201286293431\n",
      "(1460, 107)\n",
      "Test score: 0.12274784875252566\n",
      "(1460, 107)\n",
      "Test score: 0.12284042618299097\n",
      "Updating master list!\n",
      "(1460, 107)\n",
      "Test score: 0.1226738375470268\n",
      "(1460, 107)\n",
      "Test score: 0.12277444688873698\n",
      "(1460, 107)\n",
      "Test score: 0.12266248679907833\n",
      "(1460, 107)\n",
      "Test score: 0.12276009745691316\n",
      "(1460, 107)\n",
      "Test score: 0.12271360686191178\n",
      "(1460, 107)\n",
      "Test score: 0.12281344954141683\n",
      "Updating master list!\n",
      "(1460, 107)\n",
      "Test score: 0.12227271186243197\n",
      "(1460, 107)\n",
      "Test score: 0.12229219591121893\n",
      "(1460, 107)\n",
      "Test score: 0.12233325900820272\n",
      "(1460, 107)\n",
      "Test score: 0.12213250941686458\n",
      "(1460, 107)\n",
      "Test score: 0.12228481258629402\n",
      "(1460, 107)\n",
      "Test score: 0.12254779085796538\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12241562989228784\n",
      "(1460, 106)\n",
      "Test score: 0.12245770250030863\n",
      "(1460, 106)\n",
      "Test score: 0.12241445822287325\n",
      "(1460, 106)\n",
      "Test score: 0.12240098597976391\n",
      "(1460, 106)\n",
      "Test score: 0.12240777147599459\n",
      "(1460, 106)\n",
      "Test score: 0.1224056979250128\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12214066317918962\n",
      "(1460, 106)\n",
      "Test score: 0.12246202818085317\n",
      "(1460, 106)\n",
      "Test score: 0.12221192515565997\n",
      "(1460, 106)\n",
      "Test score: 0.12259465836628626\n",
      "(1460, 106)\n",
      "Test score: 0.12266275570297319\n",
      "(1460, 106)\n",
      "Test score: 0.12291253080199113\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12288818644369752\n",
      "(1460, 106)\n",
      "Test score: 0.12297537530107136\n",
      "(1460, 106)\n",
      "Test score: 0.12286331777099828\n",
      "(1460, 106)\n",
      "Test score: 0.12278556065879306\n",
      "(1460, 106)\n",
      "Test score: 0.12279292189167981\n",
      "(1460, 106)\n",
      "Test score: 0.12265900584594336\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12273862755046444\n",
      "(1460, 106)\n",
      "Test score: 0.12275029719233146\n",
      "(1460, 106)\n",
      "Test score: 0.12269501989498434\n",
      "(1460, 106)\n",
      "Test score: 0.12263919992633569\n",
      "(1460, 106)\n",
      "Test score: 0.1226959495165416\n",
      "(1460, 106)\n",
      "Test score: 0.1228501935551011\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.1225584552879348\n",
      "(1460, 106)\n",
      "Test score: 0.12252971231983051\n",
      "(1460, 106)\n",
      "Test score: 0.12265092251802917\n",
      "(1460, 106)\n",
      "Test score: 0.12260637604808211\n",
      "(1460, 106)\n",
      "Test score: 0.12258465933026415\n",
      "(1460, 106)\n",
      "Test score: 0.12249178401581089\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12256614825085743\n",
      "(1460, 106)\n",
      "Test score: 0.12260073754087185\n",
      "(1460, 106)\n",
      "Test score: 0.12257287671498353\n",
      "(1460, 106)\n",
      "Test score: 0.12253867457959307\n",
      "(1460, 106)\n",
      "Test score: 0.12254985332787109\n",
      "(1460, 106)\n",
      "Test score: 0.12250499344559668\n",
      "Updating master list!\n",
      "(1460, 107)\n",
      "Test score: 0.12250211055233845\n",
      "(1460, 107)\n",
      "Test score: 0.12248110375848022\n",
      "(1460, 107)\n",
      "Test score: 0.12250504099474456\n",
      "(1460, 107)\n",
      "Test score: 0.1225560012943654\n",
      "(1460, 107)\n",
      "Test score: 0.12254796931012447\n",
      "(1460, 107)\n",
      "Test score: 0.12262140575780169\n",
      "Updating master list!\n",
      "(1460, 107)\n",
      "Test score: 0.12244894848949975\n",
      "(1460, 107)\n",
      "Test score: 0.1224075212780172\n",
      "(1460, 107)\n",
      "Test score: 0.1224511942361031\n",
      "(1460, 107)\n",
      "Test score: 0.1224710208225109\n",
      "(1460, 107)\n",
      "Test score: 0.12246664865359147\n",
      "(1460, 107)\n",
      "Test score: 0.1224727300915706\n",
      "Updating master list!\n",
      "(1460, 107)\n",
      "Test score: 0.12323476659145555\n",
      "(1460, 107)\n",
      "Test score: 0.12404301103672642\n",
      "(1460, 107)\n",
      "Test score: 0.1225873450408005\n",
      "(1460, 107)\n",
      "Test score: 0.12235018774755765\n",
      "(1460, 107)\n",
      "Test score: 0.12248041164486703\n",
      "(1460, 107)\n",
      "Test score: 0.12264609766906592\n",
      "Updating master list!\n",
      "(1460, 107)\n",
      "Test score: 0.12250480952131688\n",
      "(1460, 107)\n",
      "Test score: 0.12253015247437833\n",
      "(1460, 107)\n",
      "Test score: 0.12250638500166368\n",
      "(1460, 107)\n",
      "Test score: 0.12261011665688538\n",
      "(1460, 107)\n",
      "Test score: 0.1226299183936531\n",
      "(1460, 107)\n",
      "Test score: 0.12305455543106657\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12261836633190965\n",
      "(1460, 106)\n",
      "Test score: 0.12241303566879037\n",
      "(1460, 106)\n",
      "Test score: 0.12273098810435067\n",
      "(1460, 106)\n",
      "Test score: 0.12261252511470569\n",
      "(1460, 106)\n",
      "Test score: 0.12248734408934055\n",
      "(1460, 106)\n",
      "Test score: 0.12231874564168617\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12217923288564711\n",
      "(1460, 106)\n",
      "Test score: 0.12190699469671487\n",
      "(1460, 106)\n",
      "Test score: 0.12221418228975996\n",
      "(1460, 106)\n",
      "Test score: 0.12241612697502002\n",
      "(1460, 106)\n",
      "Test score: 0.12223451633627874\n",
      "(1460, 106)\n",
      "Test score: 0.12235954059253892\n",
      "Updating master list!\n",
      "(1460, 107)\n",
      "Test score: 0.12186273090140415\n",
      "(1460, 107)\n",
      "Test score: 0.12185855324955451\n",
      "(1460, 107)\n",
      "Test score: 0.12186274079453632\n",
      "(1460, 107)\n",
      "Test score: 0.12184234945132563\n",
      "(1460, 107)\n",
      "Test score: 0.12185941989045915\n",
      "(1460, 107)\n",
      "Test score: 0.12186389363052688\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12197033417831447\n",
      "(1460, 106)\n",
      "Test score: 0.12197754301684746\n",
      "(1460, 106)\n",
      "Test score: 0.12197197681718629\n",
      "(1460, 106)\n",
      "Test score: 0.1219523967297178\n",
      "(1460, 106)\n",
      "Test score: 0.12194964385589735\n",
      "(1460, 106)\n",
      "Test score: 0.12193131774169158\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12232856159174528\n",
      "(1460, 106)\n",
      "Test score: 0.12407553653506183\n",
      "(1460, 106)\n",
      "Test score: 0.12320013760737325\n",
      "(1460, 106)\n",
      "Test score: 0.12405466606102687\n",
      "(1460, 106)\n",
      "Test score: 0.1240718317679548\n",
      "(1460, 106)\n",
      "Test score: 0.12272621731189076\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12192430068672588\n",
      "(1460, 106)\n",
      "Test score: 0.12193325077056763\n",
      "(1460, 106)\n",
      "Test score: 0.12193719671597139\n",
      "(1460, 106)\n",
      "Test score: 0.12193490647394321\n",
      "(1460, 106)\n",
      "Test score: 0.12351283887087881\n",
      "(1460, 106)\n",
      "Test score: 0.12196755547866911\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12186619121350895\n",
      "(1460, 106)\n",
      "Test score: 0.12249666617588265\n",
      "(1460, 106)\n",
      "Test score: 0.12206992903954562\n",
      "(1460, 106)\n",
      "Test score: 0.12257243989462806\n",
      "(1460, 106)\n",
      "Test score: 0.12259571238767464\n",
      "(1460, 106)\n",
      "Test score: 0.12378319592390473\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12181765555480129\n",
      "(1460, 106)\n",
      "Test score: 0.12178566005968022\n",
      "(1460, 106)\n",
      "Test score: 0.12182428592334311\n",
      "(1460, 106)\n",
      "Test score: 0.12180281911145721\n",
      "(1460, 106)\n",
      "Test score: 0.12196718760986053\n",
      "(1460, 106)\n",
      "Test score: 0.12175645206604485\n",
      "Updating master list!\n",
      "(1460, 106)\n",
      "Test score: 0.12178838158497657\n",
      "(1460, 106)\n",
      "Test score: 0.12177824609272558\n",
      "(1460, 106)\n",
      "Test score: 0.12179015980117329\n",
      "(1460, 106)\n",
      "Test score: 0.12179932670925259\n",
      "(1460, 106)\n",
      "Test score: 0.12179404464852706\n",
      "(1460, 106)\n",
      "Test score: 0.12182534021199237\n",
      "Updating master list!\n",
      "(1460, 106)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-340-aee807f1388d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtry_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mnew_var\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtry_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_importance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep_list\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                 \u001b[0mfeature_importances_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"feature_importances_dict\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfeature_importance\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-339-5e9134e8d3fb>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(keep_list, model, reduce_features)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"NN\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#main.cv(my_model, tr_f, targets)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIGNORE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy_X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecompute\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'l1_ratio'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_ratio_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, check_input)\u001b[0m\n\u001b[1;32m    750\u001b[0m                           \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m                           \u001b[0mselection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m                           check_input=False)\n\u001b[0m\u001b[1;32m    753\u001b[0m             \u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis_coef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m             \u001b[0mdual_gaps_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis_dual_gap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    475\u001b[0m             model = cd_fast.enet_coordinate_descent(\n\u001b[1;32m    476\u001b[0m                 \u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m                 positive)\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             raise ValueError(\"Precompute should be one of True, False, \"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import main\n",
    "from random import shuffle\n",
    "\n",
    "## Find the best transform of every feature\n",
    "\n",
    "import prep_features\n",
    "MODEL = \"ElasticNet\"\n",
    "master_list = prep_features.get_features(features, \"orig\", inverse=False) # extended variables have a __ in them\n",
    "\n",
    "# Run with all normalized values\n",
    "# Take the most important feature - find best transform - use that\n",
    "#[\"TotalSQF_normal\", \"OverallQual_normal\", \"LotArea_normal\"]\n",
    "keyword = \"Garage\"\n",
    "\n",
    "\n",
    "# Check if variable is dropped from model, ignore in this case\n",
    "# Dynamically update model\n",
    "\n",
    "best_vars = []\n",
    "#master_keep_list = prep_features.get_features(features, \"_log\") +  prep_features.get_features(features, \"_categ\") # keep only log variables\n",
    "best_score = 1\n",
    "while True:\n",
    "    shuffle(master_list)\n",
    "    \n",
    "    # Use our best set of variables\n",
    "    if 'best_keep_list' in globals():\n",
    "        master_keep_list = best_keep_list[:]\n",
    "    for keyword in master_list:\n",
    "        keyword = keyword.replace(\"_orig\", \"\")\n",
    "        keep_list = [x for x in master_keep_list if keyword not in x]   # remove the variables we're testing\n",
    "        try_list = prep_features.get_features(features, keyword) # get variables to try\n",
    "        scores = []\n",
    "        feature_importances_dict = {}\n",
    "        if len(try_list) > 1:\n",
    "            for new_var in try_list:\n",
    "                score, feature_importance, _ = run(keep_list+[new_var], model=MODEL, reduce_features=False)\n",
    "                feature_importances_dict[new_var]={\"score\":score, \"feature_importances_dict\":feature_importance}\n",
    "\n",
    "                features_kept = list(zip(*feature_importance))[1]\n",
    "                if new_var in features_kept:\n",
    "                    scores.append((score, new_var, features_kept))\n",
    "\n",
    "            # Only update if at least one variable was used and was good etc.\n",
    "            if len(scores)>0:\n",
    "                print(\"Updating master list!\")\n",
    "                scores.sort()\n",
    "                best_score_of_group = scores[0][0]\n",
    "                if best_score_of_group < best_score:\n",
    "                    best_score = best_score_of_group\n",
    "                    best_keep_list = master_keep_list[:]\n",
    "                best_var = scores[0][1]\n",
    "                best_vars.append(best_var)\n",
    "                master_used_list = scores[0][2]\n",
    "                if False:\n",
    "                    master_keep_list = keep_list[:] + [best_var]\n",
    "                else:\n",
    "                    master_keep_list = list(master_used_list)[:]\n",
    "        # Update master keep list\n",
    "\n",
    "    # PRINT BEST MODEL\n",
    "    print(\"Best model\")\n",
    "    score, feature_importance, best_model = run(master_keep_list)\n",
    "    feature_list = [x[1] for x in feature_importance]\n",
    "    print(set(feature_list))\n",
    "\n",
    "    #for score in scores:\n",
    "    #    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.11322931620975825\n",
      "Created 4950 variables for add\n",
      "Created 4950 variables for subtract\n",
      "Created 4950 variables for multiply\n",
      "Created 9801 variables for divide\n"
     ]
    }
   ],
   "source": [
    "from transforms import transform\n",
    "import pandas as pd\n",
    "from main import get_test_score\n",
    "#reimport()\n",
    "# Create model variable repository\n",
    "#main_variables = prep_features.get_features(features, \"_log\") + regression_list[:] # anything in the regression + log\n",
    "\n",
    "score, feature_importance, _ = run(model_variables, model=\"ElasticNet\", reduce_features=False)\n",
    "used_variables = list(list(zip(*feature_importance))[1]) # change model variables to the ones kept\n",
    "\n",
    "\n",
    "main_variables = used_variables[:]\n",
    "\n",
    "main_variables = list(set(main_variables))\n",
    "\n",
    "main_var_df = pd.concat([features[main_variables], test_features[main_variables]], keys=[\"train\",\"test\"], axis=0)\n",
    "\n",
    "bools = main_var_df.select_dtypes(include=[\"bool\", \"category\"]).columns\n",
    "main_var_df[bools] = main_var_df[bools].astype('int')\n",
    "                         \n",
    "# Create interactions\n",
    "additive, _ = transform(main_var_df, rename=True, replace=True, trans_type=\"add\")\n",
    "subtractive, _ = transform(main_var_df, rename=True, replace=True, trans_type=\"subtract\")\n",
    "multiplicative, _ = transform(main_var_df, rename=True, replace=True, trans_type=\"multiply\")\n",
    "divisive,_ = transform(main_var_df, rename=True, replace=True, trans_type=\"divide\")\n",
    "\n",
    "temp = pd.concat([main_var_df, additive, subtractive, multiplicative, divisive])\n",
    "huge_variable_repository = pd.concat([temp.xs(\"train\").reset_index(), features],1)\n",
    "huge_variable_repository_test = pd.concat([temp.xs(\"test\").reset_index(), test_features],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'IGNORE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1bdc6927715e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Baseline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_importance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ElasticNet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mused_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfeature_importance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# change model variables to the ones kept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-e6c3a2bc5048>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(keep_list, model, reduce_features, feats, test_feats)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mts_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeep_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtr_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeep_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_features\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mIGNORE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mts_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_targets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Lasso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'IGNORE' is not defined"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import main\n",
    "## Check if adding variable helps model\n",
    "\n",
    "import prep_features\n",
    "MODEL = \"ElasticNet\"\n",
    "\n",
    "# Baseline\n",
    "score, feature_importance, _ = run(model_variables, model=\"ElasticNet\", reduce_features=False)\n",
    "best_score = score\n",
    "used_variables = list(list(zip(*feature_importance))[1]) # change model variables to the ones kept\n",
    "\n",
    "#model_variables = regression_list[:]\n",
    "variable_repository = list(features.columns.values[:])+huge_variable_repository\n",
    "shuffle(variable_repository)\n",
    "#print(variable_repository)\n",
    "\n",
    "#get_features(features, \"_orig\")\n",
    "\n",
    "# print(len(model_variables))\n",
    "# score, feature_importance, _ = run(model_variables, model=\"ElasticNet\", reduce_features=False)\n",
    "scores = []\n",
    "while True:\n",
    "    for next_var in variable_repository:\n",
    "        score, feature_importance, _ = run(model_variables+[next_var], model=MODEL, reduce_features=False)\n",
    "        #features_kept = list(zip(*feature_importance))[1]\n",
    "        scores.append(score)\n",
    "        if next_var in features_kept and score+.0001<best_score:\n",
    "            print(\"Updating master list!\")\n",
    "            model_variables = model_variables+[next_var]\n",
    "            #list(features_kept)\n",
    "            best_score=score\n",
    "        if len(scores)>100:\n",
    "            scores = scores[-100:]\n",
    "        best_score=np.min(scores)\n",
    "\n",
    "    shuffle(model_variables)\n",
    "    print(\"Removing variables\")\n",
    "    for remove_var in model_variables:\n",
    "        score, feature_importance, _ = run([v for v in model_variables if v != remove_var], model=MODEL, reduce_features=False)\n",
    "        scores.append(score)\n",
    "        if score+.0001<best_score:\n",
    "            print(\"Updating master list!\")\n",
    "            model_variables.remove(remove_var)\n",
    "            #list(features_kept)\n",
    "        if len(scores)>100:\n",
    "            scores = scores[-100:]\n",
    "        best_score=np.min(scores)\n",
    "\n",
    " \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Test score: 0.11322444121806956\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'huge_variable_repository' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-42155eaae2b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#model_variables = regression_list[:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mvariable_repository\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mhuge_variable_repository\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_repository\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'huge_variable_repository' is not defined"
     ]
    }
   ],
   "source": [
    "## RANDOM ONE\n",
    "from main import get_test_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if False:\n",
    "    features = pd.concat([features,huge_variable_repository],1)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import main\n",
    "## Check if adding variable helps model\n",
    "import prep_features\n",
    "MODEL = \"ElasticNet\"\n",
    "\n",
    "# Baseline\n",
    "score, feature_importance, _ = run(model_variables, model=\"ElasticNet\", reduce_features=False)\n",
    "best_score = score\n",
    "used_variables = list(list(zip(*feature_importance))[1]) # change model variables to the ones kept\n",
    "\n",
    "#model_variables = regression_list[:]\n",
    "variable_repository = list(features.columns.values[:])+huge_variable_repository.columns\n",
    "shuffle(variable_repository)\n",
    "\n",
    "scores = []\n",
    "while True:\n",
    "    r = random.randint(0,len(variable_repository))\n",
    "    next_var = variable_repository[r]\n",
    "    score, feature_importance, _ = run(model_variables+[next_var], model=MODEL, reduce_features=False)\n",
    "    #features_kept = list(zip(*feature_importance))[1]\n",
    "    scores.append(score)\n",
    "    if next_var in features_kept and score+.0001<best_score:\n",
    "        print(\"Updating master list! Adding {}\".format(next_var))\n",
    "        model_variables = model_variables+[next_var]\n",
    "        #list(features_kept)\n",
    "        best_score=score\n",
    "    if len(scores)>100:\n",
    "        scores = scores[-100:]\n",
    "    best_score=np.min(scores)\n",
    "\n",
    "    r2 = random.randint(0,len(model_variables))\n",
    "    remove_var = model_variables[r2]\n",
    "    score, feature_importance, _ = run([v for v in model_variables if v != remove_var], model=MODEL, reduce_features=False)\n",
    "    scores.append(score)\n",
    "    if score+.0001<best_score:\n",
    "        print(\"Updating master list! Removing {}\".format(remove_var))\n",
    "        model_variables.remove(remove_var)\n",
    "        #list(features_kept)\n",
    "    if len(scores)>100:\n",
    "        scores = scores[-100:]\n",
    "    best_score=np.min(scores)\n",
    "\n",
    " \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_variables = ['Heating_Floor_orig_categ', 'SaleType_Con_orig_categ', 'SaleType_COD_orig_categ', 'HouseStyle_2.5Fin_orig_categ', 'KitchenAbvGr_cont_trans_root', 'Condition1_RRAe_orig_categ', 'Neighborhood_Somerst_orig_categ', 'Electrical_Mix_orig_categ', 'Condition1_PosA_orig_categ', 'CentralAir_ord_trans_inverse', 'SQFperRoom_cont_trans_quadratic', 'Exterior2nd_ImStucc_orig_categ', 'Neighborhood_Crawfor_orig_categ', 'GarageType_2Types_orig_categ', 'Street_Grvl_orig_categ', 'Season_3_orig_categ', 'Neighborhood_IDOTRR_orig_categ', 'BedroomAbvGr_cont_trans_normal', 'HouseStyle_1Story_orig_categ', 'Exterior2nd_Plywood_orig_categ', 'LandContour_Low_orig_categ', 'BsmtUnfSF_cont_trans_normal', 'RoofStyle_Flat_orig_categ', 'GarageArea_cont_trans_scale01', 'FireplaceQu_ord_trans_log', 'MSZoning_FV_orig_categ', 'Electrical_FuseP_orig_categ', 'ScreenPorch_cont_trans_normal', 'OverallQual_cont_trans_root', 'Foundation_Slab_orig_categ', 'MSZoning_RH_orig_categ', 'SaleCondition_Family_orig_categ', 'TotalSQF_cont_trans_normal', 'Heating_Wall_orig_categ', 'LotShape_Reg_orig_categ', 'SaleCondition_Abnorml_orig_categ', 'GarageType_Detchd_orig_categ', 'HouseAge_cont_trans_normal', 'Neighborhood_Mitchel_orig_categ', 'Neighborhood_NWAmes_orig_categ', 'Neighborhood_Veenker_orig_categ', 'Neighborhood_Sawyer_orig_categ', 'Condition2_PosA_orig_categ', 'Neighborhood_Blueste_orig_categ', 'HasPool_orig_categ', 'Neighborhood_BrDale_orig_categ', 'YrSold_2007_orig_categ', 'RoofMatl_ClyTile_orig_categ', 'Neighborhood_MeadowV_orig_categ', 'Condition1_PosN_orig_categ', 'MSZoning_RL_orig_categ', 'Neighborhood_OldTown_orig_categ', 'MSSubClass_120_orig_categ', 'TotalBsmtSF_cont_trans_quadratic', 'ExterQual_ord_trans_scale01', 'Exterior1st_BrkFace_orig_categ', 'Street_Pave_orig_categ', 'BsmtExposure_ord_trans_quadratic', 'Exterior1st_Stone_orig_categ', 'YrSold_2006_orig_categ', 'Electrical_FuseF_orig_categ', 'BsmtFinType1_ord_trans_quadratic', 'MSSubClass_60_orig_categ', 'Exterior2nd_Wd Sdng_orig_categ', 'MSSubClass_180_orig_categ', 'Exterior2nd_CmentBd_orig_categ', 'Foundation_Wood_orig_categ', 'MasVnrArea_cont_trans_normal', 'Alley_Grvl_orig_categ', 'YrSold_2010_orig_categ', '2ndFlrSF_cont_trans_root', 'MSSubClass_30_orig_categ', 'BsmtFullBath_cont_trans_root', '3SsnPorch_cont_trans_quadratic', 'Exterior2nd_MetalSd_orig_categ', 'LotShape_IR2_orig_categ', 'SaleType_ConLD_orig_categ', 'Condition2_RRNn_orig_categ', 'Neighborhood_NridgHt_orig_categ', 'MSSubClass_50_orig_categ', 'SaleCondition_AdjLand_orig_categ', 'Condition1_Feedr_orig_categ', 'GarageIdx_cont_trans_root', 'Exterior1st_MetalSd_orig_categ', 'HouseStyle_SFoyer_orig_categ', 'Neighborhood_NAmes_orig_categ', 'Condition1_Artery_orig_categ', 'HeatingQC_ord_trans_normal', 'Exterior2nd_Other_orig_categ', 'HouseStyle_1.5Unf_orig_categ', 'RoofStyle_Gambrel_orig_categ', 'GrLivArea_cont_trans_log', 'RemodelAge_cont_trans_log', 'Season_1_orig_categ', 'BsmtCond_ord_trans_normal', 'Neighborhood_Edwards_orig_categ', 'GarageFinish_ord_trans_normal', 'Exterior1st_CemntBd_orig_categ', 'LandContour_Bnk_orig_categ', 'MSSubClass_190_orig_categ', 'Heating_GasA_orig_categ', 'LargeHouse_orig_categ', 'Exterior2nd_AsphShn_orig_categ', 'RoofMatl_Roll_orig_categ', 'PavedDrive_ord_trans_quadratic', 'Heating_OthW_orig_categ', 'Neighborhood_NoRidge_orig_categ', 'SummerSale_orig_categ', 'BldgType_2fmCon_orig_categ', 'RoofMatl_WdShake_orig_categ', 'Exterior1st_ImStucc_orig_categ', 'Foundation_CBlock_orig_categ', 'TotRmsAbvGrd_cont_trans_normal', 'Exterior1st_BrkComm_orig_categ', 'HouseStyle_1.5Fin_orig_categ', 'GarageType_BuiltIn_orig_categ', 'OverallCond_cont_trans_log', 'LotFrontage_cont_trans_quadratic', 'YrSold_2009_orig_categ', 'LotArea_cont_trans_log', 'BldgType_1Fam_orig_categ', 'GarageCond_ord_trans_quadratic', 'SaleType_ConLw_orig_categ', 'MiscFeature_TenC_orig_categ', 'Exterior1st_VinylSd_orig_categ', 'LandContour_Lvl_orig_categ', 'Exterior2nd_BrkFace_orig_categ', 'Exterior2nd_CBlock_orig_categ', 'Neighborhood_Gilbert_orig_categ', 'Condition2_Artery_orig_categ', 'SaleType_New_orig_categ', 'RoofStyle_Gable_orig_categ', 'SaleCondition_Partial_orig_categ', 'Neighborhood_ClearCr_orig_categ', 'Foundation_Stone_orig_categ', 'RoofMatl_Membran_orig_categ', 'RoofMatl_Metal_orig_categ', 'MSSubClass_70_orig_categ', 'Functional_ord_trans_scale01', 'YrSold_2008_orig_categ', 'Neighborhood_CollgCr_orig_categ', 'LandContour_HLS_orig_categ', 'MiscVal_cont_trans_root', 'Fence_ord_trans_quadratic', 'Neighborhood_NPkVill_orig_categ', 'PoolQC_ord_trans_quadratic', '1stFlrSF_cont_trans_quadratic', 'LotConfig_FR3_orig_categ', 'BsmtQual_ord_trans_scale01', 'SaleCondition_Alloca_orig_categ', 'NewHouse_orig_categ', 'LotShape_IR1_orig_categ', 'Exterior2nd_AsbShng_orig_categ', 'Id', 'MSSubClass_20_orig_categ', 'Exterior2nd_HdBoard_orig_categ', 'ExterCond_ord_trans_scale01', 'HouseStyle_2Story_orig_categ', 'Exterior2nd_Brk Cmn_orig_categ', 'RoofStyle_Shed_orig_categ', 'FullBath_cont_trans_quadratic', 'HouseStyle_2.5Unf_orig_categ', 'Alley_Pave_orig_categ', 'RoofMatl_Tar&Grv_orig_categ', 'Exterior1st_CBlock_orig_categ', 'LotConfig_FR2_orig_categ', 'RoofStyle_Mansard_orig_categ', 'PoolArea_cont_trans_root', 'Condition2_RRAe_orig_categ', 'LandSlope_Gtl_orig_categ', 'MiscFeature_Othr_orig_categ', 'MSSubClass_80_orig_categ', 'Fireplaces_cont_trans_normal', 'RoofStyle_Hip_orig_categ', 'Exterior1st_WdShing_orig_categ', 'Condition2_Feedr_orig_categ', 'MiscFeature_Shed_orig_categ', 'Neighborhood_Blmngtn_orig_categ', 'RoofMatl_WdShngl_orig_categ', 'Electrical_SBrkr_orig_categ', 'Exterior1st_Wd Sdng_orig_categ', 'BldgType_Twnhs_orig_categ', 'MSSubClass_45_orig_categ', 'BsmtFinSF1_cont_trans_normal', 'EnclosedPorch_cont_trans_quadratic', 'LotConfig_Corner_orig_categ', 'GarageType_CarPort_orig_categ', 'KitchenQual_ord_trans_scale01', 'SaleType_ConLI_orig_categ', 'Foundation_BrkTil_orig_categ', 'Foundation_PConc_orig_categ', 'Exterior2nd_Stucco_orig_categ', 'PrchSQ_cont_trans_quadratic', 'Exterior1st_Plywood_orig_categ', 'GarageType_0_orig_categ', 'MiscFeature_Gar2_orig_categ', 'BsmtFinType2_ord_trans_quadratic', 'Heating_GasW_orig_categ', 'SaleType_Oth_orig_categ', 'LotShape_IR3_orig_categ', 'Exterior2nd_VinylSd_orig_categ', 'SaleType_CWD_orig_categ', 'HouseStyle_SLvl_orig_categ', 'Exterior1st_Stucco_orig_categ', 'Condition2_Norm_orig_categ', 'Neighborhood_SWISU_orig_categ', 'MSSubClass_85_orig_categ', 'BldgType_TwnhsE_orig_categ', 'BldgType_Duplex_orig_categ', 'WoodDeckSF_cont_trans_scale01', 'GarageType_Attchd_orig_categ', 'MSSubClass_40_orig_categ', 'GarageAgeInv_cont_trans_normal', 'BsmtHalfBath_cont_trans_normal', 'Neighborhood_StoneBr_orig_categ', 'GarageType_Basment_orig_categ', 'MasVnrType_ord_trans_root', 'LandSlope_Mod_orig_categ', 'Condition1_RRNn_orig_categ', 'BsmtFinSF2_cont_trans_quadratic', 'Condition1_RRAn_orig_categ', 'MSSubClass_160_orig_categ', 'Neighborhood_SawyerW_orig_categ', 'RoofMatl_CompShg_orig_categ', 'Exterior1st_AsbShng_orig_categ', 'Condition2_RRAn_orig_categ', 'Exterior1st_HdBoard_orig_categ', 'LandSlope_Sev_orig_categ', 'MSSubClass_90_orig_categ', 'Neighborhood_Timber_orig_categ', 'Season_0_orig_categ', 'Exterior2nd_Wd Shng_orig_categ', 'Utilities_ord_trans_quadratic', 'OpenPorchSF_cont_trans_normal', 'Exterior2nd_Stone_orig_categ', 'MSSubClass_75_orig_categ', 'Exterior1st_AsphShn_orig_categ', 'MoSold_cont_trans_normal', 'Season_2_orig_categ', 'Heating_Grav_orig_categ', 'Electrical_FuseA_orig_categ', 'LowQualFinSF_cont_trans_root', 'KitchenAbvGr_cont_trans_root', 'Neighborhood_Somerst_orig_categ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.1132299387797898\n",
      "CV score: 0.12379230312397893\n",
      "[116163.8104243  159114.27543278 181928.26635747 ... 161645.20634045\n",
      " 121973.87541934 222090.75959493]\n",
      "0       105001.0\n",
      "1       172001.0\n",
      "2       189901.0\n",
      "3       195501.0\n",
      "4       191501.0\n",
      "5       175901.0\n",
      "6       185001.0\n",
      "7       180401.0\n",
      "8       171501.0\n",
      "9       126001.0\n",
      "          ...   \n",
      "1449     73001.0\n",
      "1450     79401.0\n",
      "1451    140001.0\n",
      "1452     87551.0\n",
      "1453     79501.0\n",
      "1454     90501.0\n",
      "1455     71001.0\n",
      "1456    131001.0\n",
      "1457    132001.0\n",
      "1458    188001.0\n",
      "Name: SalePrice, Length: 1459, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Run one\n",
    "#regression_list = master_keep_list[:]\n",
    "\n",
    "keep_variables = model_variables[:]\n",
    "_, _, my_model = run(keep_variables, model=\"ElasticNet\")\n",
    "prediction = my_model.predict(test_features[keep_variables])\n",
    "main.cv(my_model, features, targets)\n",
    "export(ex_path, test_targets, prediction)\n",
    "\n",
    "print(np.exp(prediction))\n",
    "print(np.exp(test_targets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import export_data\n",
    "\n",
    "def export(path, test, prediction):\n",
    "    ex_path = \"/medic/github/housing-prices/output/ensemble.csv\"\n",
    "    prediction = np.exp(prediction)-1\n",
    "    ids = np.array(range(1461,1461+test.shape[0]))\n",
    "    submission_df = pd.concat([pd.Series(ids),pd.DataFrame(prediction, columns=[\"SalePrice\"])], axis=1)\n",
    "    submission_df.columns = [\"Id\", \"SalePrice\"]\n",
    "    export_data.export_data(submission_df, path)\n",
    "\n",
    "#export(ex_path, my_model.model, features.values)\n",
    "#export(ex_path, my_model.model, test_features.values)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
